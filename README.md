# Neural_net_from_Scratch

# Building a Neural Network from Scratch ðŸš€

This repository demonstrates how to build a neural network from scratch without using high-level deep learning frameworks like TensorFlow or PyTorch. The goal is to understand the core principles of neural networks by implementing them with just NumPy.

---

## ðŸ§  Project Overview

This project walks through the step-by-step process of creating a fully functional feedforward neural network:
- Implementing forward propagation
- Applying activation functions (e.g., ReLU, Sigmoid, etc.)
- Calculating loss using cost functions
- Backpropagation for parameter updates
- Training the model on a simple dataset

---

## âœ¨ Features

- **Customizable Architecture**: Easily modify the number of layers, neurons, and activation functions.
- **Activation Functions**: Includes ReLU, Sigmoid, and Softmax implementations.
- **Training & Testing**: Train the network on a sample dataset and evaluate its performance.
- **Fully Transparent**: Every component is implemented from scratch using NumPy for clarity and learning purposes.

---



